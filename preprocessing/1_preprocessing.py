# -*- coding: utf-8 -*-
"""1_Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lEO8y5xHXZuptb6BFssKZj0tByYnSmP8

# **1. Data Preprocessing**
- [Dataset Download](https://www.kaggle.com/uciml/sms-spam-collection-dataset)

## 1-1. 데이터 확인

우선, kaggle에서 제공하는 데이터셋을 다운받습니다.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
# %matplotlib inline
import matplotlib.pyplot as plt
import urllib.request

urllib.request.urlretrieve("https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv", filename="spam.csv")
data = pd.read_csv('spam.csv',encoding='latin1')

print('총 데이터 수 :',len(data))

"""우선 데이터 확인을 위해 기존 데이터에서 **상위 10개**만 추출하여 확인해봅니다."""

data[:10]

"""## 1-2.불필요한 열 제거

불필요한 열 : `Unnamed: n`

위 3개의 열은 텍스트 분류를 진행하기엔 불필요한 열입니다.

위 3개의 열을 삭제하고 2개의 열(`v1`,`v2`)를 (`category`, `text`)로 변경합니다.
"""

data = data[data.columns[:2]] # 두열만 가져온다. 
data.columns = ['category', 'text']

data

"""해당 데이터의 정보 확인"""

data.info()

"""`null`값 확인"""

data.isnull().values.any()

"""중복 데이터 확인"""

data['text'].nunique(), data['category'].nunique()

df = pd.DataFrame(data)
duplicatedDF = df[df.duplicated()]
print(duplicatedDF)

"""5,572개 중  `403`개의 중복 데이터가 존재한다는 것을 확인하였습니다."""

data.drop_duplicates(subset=['text'], inplace=True)

df = pd.DataFrame(data)
print(df)  # 출력 DataFrame

"""## 1-3. 시각화) 메세지 길이 분포

우선 `groupby`를 이용하여 기본적인 갯수나 빈도수를 확인하였습니다.
"""

data.groupby('category').describe()

data['category_01'] = data.category.map({'ham':0, 'spam':1})

data['text_length'] = data.text.apply(len)

fix, ax = plt.subplots(1,2, figsize=(12,4))

data[data.category=='ham'].hist(column='text_length', bins=50,ax=ax[0],color = 'green')
ax[0].set(xlabel = 'Message Length',ylabel = 'Frequency',title = 'HAM', xlim = (0, 250))
data[data.category=='spam'].hist(column='text_length', bins=50,ax=ax[1],color = 'red')
ax[1].set(xlabel = 'Message Length',ylabel = 'Frequency',title = 'SPAM', xlim = (0, 250));

"""메세지의 빈도수를 보게되면 스팸의 메시지는 주로 150글자 정도되며, 스팸이 아닌 일반 메세지는 그보다 적인 50글자 내외가 가장 많음을 확인할 수 있습니다."""

data['category'].value_counts().plot(kind='bar');

"""스팸보다 일반 메세지의 비율이 가장 많다는 것을 확인할 수 있다."""

print(data.groupby('category').size().reset_index(name='count'))

"""## 1-4. WordCloud"""

X_data = data['text']
y_data = data['category']

import seaborn as sns
import re
import warnings
from wordcloud import WordCloud, STOPWORDS
from collections import Counter
import nltk 
from nltk.corpus import stopwords
warnings.filterwarnings('ignore')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline 설정을 해주어야지만 노트북 안에 그래프가 디스플레이 된다.
# %matplotlib inline

def displayWordCloud(data = X_data, backgroundcolor = 'white', width=800, height=600 ):
    wordcloud = WordCloud(stopwords = STOPWORDS, 
                          background_color = backgroundcolor, 
                         width = width, height = height).generate(data)
    plt.figure(figsize = (15 , 10))
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %time displayWordCloud(''.join(X_data))

# Commented out IPython magic to ensure Python compatibility.
data_spam = data[data['category']== 'spam']

X_spam_data = data_spam['text']
y_spam_data = data_spam['category']

def displayWordCloud(data = None, backgroundcolor = 'white', width=800, height=600 ):
    wordcloud = WordCloud(stopwords = STOPWORDS, 
                          background_color = backgroundcolor, 
                         width = width, height = height).generate(data)
    plt.figure(figsize = (15 , 10))
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.show() 

# %time displayWordCloud(''.join(X_spam_data))

# Commented out IPython magic to ensure Python compatibility.
data_ham = data[data['category']== 'ham']

X_hdata = data_ham['text']
y_hdata = data_ham['category']


def displayWordCloud(data = None, backgroundcolor = 'white', width=800, height=600 ):
    wordcloud = WordCloud(stopwords = STOPWORDS, 
                          background_color = backgroundcolor, 
                         width = width, height = height).generate(data)
    plt.figure(figsize = (15 , 10))
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.show() 

# %time displayWordCloud(''.join(X_hdata))

